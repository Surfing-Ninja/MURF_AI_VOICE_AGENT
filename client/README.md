# ğŸ™ï¸ Voice Agent Frontend (React + Vite)

High-performance frontend for the Multimodal Voice Agent with real-time audio streaming.

## ğŸ¯ Features

- âœ… **Real-time Audio Streaming**: 250ms timeslice for low-latency
- âœ… **Custom Audio Hook**: `useAudioRecorder.js` for microphone management
- âœ… **WebSocket Integration**: Bidirectional communication with backend
- âœ… **Automatic Resampling**: Browser handles 48kHz â†’ 16kHz conversion
- âœ… **Smart Permissions**: Handles mic permissions gracefully
- âœ… **Error Handling**: User-friendly error messages
- âœ… **Emotion Display**: Shows AI response emotions
- âœ… **Clean UI**: Modern, responsive design

## ğŸ“ Project Structure

```
client/
â”œâ”€â”€ package.json                 # Dependencies (React 18, Vite 5)
â”œâ”€â”€ vite.config.js               # Vite configuration
â”œâ”€â”€ index.html                   # HTML template
â””â”€â”€ src/
    â”œâ”€â”€ main.jsx                 # React entry point
    â”œâ”€â”€ App.jsx                  # Main application component
    â”œâ”€â”€ App.css                  # Application styles
    â”œâ”€â”€ index.css                # Global styles
    â””â”€â”€ hooks/
        â”œâ”€â”€ useAudioRecorder.js  # â­ Custom audio recording hook
        â””â”€â”€ useWebSocket.js      # WebSocket connection hook
```

## ğŸš€ Quick Start

### Installation

```bash
cd client
npm install
```

### Development

```bash
npm run dev
```

Open: **http://localhost:5173**

### Production Build

```bash
npm run build
npm run preview
```

## ğŸ¤ useAudioRecorder Hook

The core hook for handling microphone input with low-latency streaming.

### Features

- âœ… MediaRecorder API with **250ms timeslice**
- âœ… Automatic WebSocket streaming
- âœ… Proper cleanup on stop
- âœ… Error handling with user-friendly messages
- âœ… Microphone permission management

### API

```javascript
const { startRecording, stopRecording, isRecording, error } = useAudioRecorder(websocket);
```

**Returns:**
- `startRecording()` - Start recording from microphone
- `stopRecording()` - Stop recording and cleanup
- `isRecording` - Boolean recording state
- `error` - Error message (if any)

### Usage Example

```javascript
import { useState } from 'react';
import useWebSocket from './hooks/useWebSocket';
import useAudioRecorder from './hooks/useAudioRecorder';

function App() {
  const { ws, isConnected } = useWebSocket('ws://localhost:3000');
  const { startRecording, stopRecording, isRecording } = useAudioRecorder(ws);

  return (
    <button 
      onClick={isRecording ? stopRecording : startRecording}
      disabled={!isConnected}
    >
      {isRecording ? 'Stop' : 'Start'} Recording
    </button>
  );
}
```

## ğŸ”§ Technical Details

### Audio Configuration

```javascript
{
  audio: {
    channelCount: 1,           // Mono audio
    sampleRate: 16000,         // 16kHz (Deepgram requirement)
    echoCancellation: true,    // Reduce echo
    noiseSuppression: true,    // Remove background noise
    autoGainControl: true      // Normalize volume
  }
}
```

### MediaRecorder Configuration

```javascript
{
  mimeType: 'audio/webm;codecs=opus',  // Or fallback to 'audio/webm'
  audioBitsPerSecond: 128000           // 128 kbps
}
```

### Streaming Logic

```javascript
mediaRecorder.ondataavailable = (event) => {
  if (event.data.size > 0) {
    // Check WebSocket is open
    if (websocket && websocket.readyState === WebSocket.OPEN) {
      console.log(`ğŸ“¤ Sending audio chunk: ${event.data.size} bytes`);
      websocket.send(event.data);  // Send binary Blob
    }
  }
};

// Start with 250ms timeslice for low latency
mediaRecorder.start(250);
```

## ğŸŒ WebSocket Protocol

### Messages Sent to Server

**1. Start Recording**
```json
{
  "type": "start_recording",
  "timestamp": 1234567890123
}
```

**2. Audio Data**
```
Binary Blob (audio/webm)
Sent every 250ms
```

**3. Stop Recording**
```json
{
  "type": "stop_recording",
  "timestamp": 1234567890123
}
```

### Messages Received from Server

**1. Transcript**
```json
{
  "type": "transcript",
  "text": "What is your refund policy?",
  "isFinal": true,
  "timestamp": 1234567890123
}
```

**2. AI Response**
```json
{
  "type": "ai_response",
  "text": "We offer a 30-day money-back guarantee",
  "emotion": "neutral",
  "timestamp": 1234567890123
}
```

**3. Error**
```json
{
  "type": "error",
  "message": "Failed to generate AI response",
  "timestamp": 1234567890123
}
```

**4. STT Ready**
```json
{
  "type": "stt_ready",
  "message": "Speech-to-text ready",
  "timestamp": 1234567890123
}
```

## ğŸ¨ UI Components

### Recording Button
- **Idle State**: Blue gradient with ğŸ¤ icon
- **Recording State**: Red gradient with ğŸ”´ icon, pulsing animation
- **Disabled State**: Greyed out when WebSocket disconnected

### Status Indicator
- **Connected**: Green dot with "Connected" label
- **Disconnected**: Red dot with "Disconnected" label

### Transcript Display
- Shows user's speech after Deepgram transcription
- Left border in blue gradient
- Icon: ğŸ‘¤

### AI Response Display
- Shows AI's response with emotion badge
- Left border in purple gradient
- Icon: ğŸ¤–
- Emotion badges: happy (green), sad (blue), angry (red), neutral (gray)

## ğŸ› ï¸ Error Handling

The hook handles common errors gracefully:

### Microphone Errors

| Error | Message | Resolution |
|-------|---------|------------|
| `NotAllowedError` | Microphone access denied | User must allow permissions |
| `NotFoundError` | No microphone found | Connect a microphone |
| `NotReadableError` | Mic in use by another app | Close other apps using mic |

### WebSocket Errors

| Error | Behavior | Resolution |
|-------|----------|------------|
| Connection lost | Auto-reconnect in 3s | Wait or refresh page |
| Not connected | Disable recording button | Wait for connection |

## ğŸ” Debugging

Enable verbose logging:

```javascript
// In useAudioRecorder.js
console.log('ğŸ¤ Recording started with 250ms timeslice');
console.log('ğŸ“¤ Sending audio chunk:', event.data.size, 'bytes');
console.log('ğŸ›‘ Recording stopped');
console.log('ğŸ”‡ Microphone track stopped');
```

### Check Browser Console

- `ğŸ¤` = Recording events
- `ğŸ“¤` = Audio chunks sent
- `ğŸ“¨` = Messages received
- `âœ“` = Success
- `âŒ` = Errors
- `âš ï¸` = Warnings

## ğŸ“Š Performance

- **Latency**: ~250ms from speech to server
- **Audio Quality**: 128 kbps (good balance)
- **Chunk Size**: ~32KB per 250ms
- **Memory**: Minimal (no buffering)

## ğŸ” Security

- HTTPS required for `getUserMedia()` in production
- WebSocket should use WSS (secure WebSocket)
- No audio data stored in browser
- Microphone access requires explicit user permission

## ğŸš€ Deployment

### Build for Production

```bash
npm run build
```

Output: `dist/` folder

### Deploy to Static Host

```bash
# Example: Vercel
vercel deploy

# Example: Netlify
netlify deploy --prod

# Example: GitHub Pages
npm run build
gh-pages -d dist
```

### Environment Variables

Create `.env` file:

```bash
VITE_WS_URL=wss://your-backend.com
```

Update `App.jsx`:

```javascript
const WS_URL = import.meta.env.VITE_WS_URL || 'ws://localhost:3000';
```

## ğŸ§ª Testing

### Manual Testing

1. **Microphone Access**:
   - Click "Start Talking"
   - Allow microphone permission
   - Verify recording indicator appears

2. **Audio Streaming**:
   - Speak for 5+ seconds
   - Check console for "ğŸ“¤ Sending audio chunk" logs
   - Verify chunks sent every ~250ms

3. **WebSocket Connection**:
   - Check status indicator is green
   - Kill backend, verify auto-reconnect
   - Verify recording disabled when disconnected

4. **Error Handling**:
   - Deny mic permission â†’ See error banner
   - Disconnect mic â†’ See error message

### Browser Compatibility

| Browser | Version | Status |
|---------|---------|--------|
| Chrome | 90+ | âœ… Fully supported |
| Firefox | 88+ | âœ… Fully supported |
| Safari | 14+ | âœ… Fully supported |
| Edge | 90+ | âœ… Fully supported |

## ğŸ“š Dependencies

```json
{
  "react": "^18.3.1",           // UI framework
  "react-dom": "^18.3.1",       // DOM rendering
  "@vitejs/plugin-react": "^4.3.4",  // Vite React plugin
  "vite": "^5.4.11"             // Build tool
}
```

**Total Size**: ~150KB (minified + gzipped)

## ğŸ¯ Next Steps

- [ ] Add audio visualization (waveform/spectrum)
- [ ] Implement TTS audio playback from Murf
- [ ] Add screen capture for multimodal vision
- [ ] Support conversation history UI
- [ ] Add voice activity detection (VAD)
- [ ] Implement push-to-talk mode

## ğŸ“– API Reference

### useAudioRecorder(websocket)

**Parameters:**
- `websocket` (WebSocket|null) - Active WebSocket connection

**Returns:**
```typescript
{
  startRecording: () => Promise<void>,
  stopRecording: () => void,
  isRecording: boolean,
  error: string | null
}
```

### useWebSocket(url)

**Parameters:**
- `url` (string) - WebSocket server URL

**Returns:**
```typescript
{
  ws: WebSocket | null,
  isConnected: boolean,
  error: string | null,
  sendMessage: (data: object) => void,
  connect: () => void,
  disconnect: () => void
}
```

## ğŸ’¡ Tips

1. **Latency Optimization**: 250ms is optimal balance between latency and bandwidth
2. **Sample Rate**: 16kHz is required by Deepgram Nova-2
3. **Mono Audio**: Single channel reduces bandwidth by 50%
4. **Echo Cancellation**: Critical for speaker + mic scenarios
5. **Noise Suppression**: Improves transcription accuracy

## ğŸ› Troubleshooting

**Q: No audio chunks being sent?**
- Check WebSocket connection status (should be green)
- Verify microphone permissions are granted
- Check browser console for errors
- Ensure backend is running on port 3000

**Q: Getting ScriptProcessorNode deprecation warning?**
- This is a browser warning and won't affect functionality
- The warning comes from internal browser audio processing
- Modern browsers handle this automatically
- Can be safely ignored (will be fixed in future browser updates)

**Q: WebSocket connects but no transcripts?**
- Verify backend Deepgram configuration uses `webm-opus` encoding
- Check backend console for "Sending audio chunk to Deepgram" logs
- Ensure Deepgram API key is valid in backend `.env`
- Check if audio chunks are actually being sent (look for ğŸ“¤ logs)

**Q: High latency?**
- Reduce timeslice (but increases bandwidth)
- Check network connection
- Verify backend processing speed

**Q: Poor audio quality?**
- Increase `audioBitsPerSecond`
- Check microphone quality
- Reduce background noise

**Q: MediaRecorder not supported?**
- Update browser to latest version
- Check browser compatibility table
- Use polyfill for older browsers

## ğŸ“ License

MIT License - Part of Voice Agent project

---

**Built with â¤ï¸ using React + Vite**
